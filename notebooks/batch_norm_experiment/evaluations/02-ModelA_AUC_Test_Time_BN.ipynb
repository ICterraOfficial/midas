{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T07:46:33.307126Z",
     "iopub.status.busy": "2024-01-23T07:46:33.306517Z",
     "iopub.status.idle": "2024-01-23T07:46:33.316159Z",
     "shell.execute_reply": "2024-01-23T07:46:33.314715Z",
     "shell.execute_reply.started": "2024-01-23T07:46:33.307080Z"
    }
   },
   "source": [
    "## Info\n",
    "---\n",
    "\n",
    "This notebook is designed to compare model's performance on the different datasets using test-time BN statistics.\n",
    "<br>\n",
    "\n",
    "\n",
    "| Dataset | Model | Pretrained Model         | Hyper-parameters | Notes |\n",
    "| :--- | :--- |:-------------------------| :--- | :--- |\n",
    "| HospitalA/test.xlsx | HospitalA | HospitalA/best_model.pth | Patch size: 256x256 <br> Patch count: 6 | Loss: BCE+L1Norm |\n",
    "\n",
    "<br>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "\n",
    "from data import ClassificationDataset\n",
    "from data import Transforms as T\n",
    "from models import GMIC\n",
    "from models.EvaluationTools import MetricCalculator\n",
    "from utils.Config import Config\n",
    "from visualization import plot_roc_pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = 'cuda'\n",
    "\n",
    "training_name = 'YYYY_MM_DD_HospitalA_BNFC'\n",
    "\n",
    "cfg_path = f'../../../models/Experiment1/{training_name}/config.yaml'\n",
    "weight_path = f'../../../models/Experiment1/{training_name}/weights/best_model.pth'\n",
    "\n",
    "cfg = Config(cfg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_size = 8\n",
    "\n",
    "transforms = {'dicom': [T.FlipToLeft(), T.CropBreastRegion(),\n",
    "                        T.Resize(height=cfg.data.inp_height, width=cfg.data.inp_width),\n",
    "                        T.UIntToFloat32(), T.StandardScoreNormalization()]\n",
    "             }"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_dataloader(dataset_path):\n",
    "    \"\"\"\n",
    "    Loads a classification dataset from the specified path and returns a PyTorch DataLoader.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = ClassificationDataset(dataset_path, transform=transforms)\n",
    "\n",
    "    if not 'Cancer' in dataset.metadata.keys():\n",
    "        dataset.metadata['Cancer'] = dataset.metadata.OneHotLabel.apply(lambda label: 1 if label==[0, 1] else 0)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare the datasets for evaluation.\n",
    "dataset1_path = '../../../data/processed/HospitalA/test.xlsx'\n",
    "dataset2_path = '../../../data/processed/HospitalB/test.xlsx'\n",
    "dataset3_path = '../../../data/processed/HospitalC/test.xlsx'\n",
    "\n",
    "dataset_paths = (dataset1_path, dataset2_path, dataset3_path)\n",
    "dataset_names = ('Dataset1', 'Dataset2', 'Dataset3')\n",
    "\n",
    "dataloaders = []\n",
    "\n",
    "for i, path in enumerate(dataset_paths):\n",
    "    dataloader = create_dataloader(path)\n",
    "    dataloaders.append((dataset_names[i], dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GMIC(cfg.gmic_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(weight_path)\n",
    "model.load_state_dict(weights, strict=False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# To use test-time BN statistics, enable training mode.\n",
    "# This will update BN statistics for each batch. Higher batch size can yield more stable results.\n",
    "model.train()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric calculator to store predictions and calculate metrics.\n",
    "metric_calculator = MetricCalculator()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_predictions(dataset_name, data_loader, model):\n",
    "    # Create a progressbar to monitor evaluatin progress.\n",
    "    meta_data = data_loader.dataset.metadata\n",
    "    prog_bar = tqdm.tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    prog_bar.set_description(f\"{dataset_name} \")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (breast_ids, batch_dicom, batch_true) in prog_bar:  # batch_ground_truth\n",
    "            batch_dicom = batch_dicom.unsqueeze(1).to(device)\n",
    "\n",
    "            # Forward pass and make prediction.\n",
    "            predictions = model(batch_dicom)\n",
    "            metric_calculator.store_preds_truths(breast_ids, predictions['fusion'], batch_true)\n",
    "            \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Update positive_class dimesion of predictions for benign class. \n",
    "    # Prediction indices [[benign_pred1, malign_pred1],\n",
    "    #                     [benign_pred2, malign_pred2]]\n",
    "    benign_metrics = metric_calculator.calculate_metrics(positive_class_dim=0)\n",
    "    malign_metrics = metric_calculator.calculate_metrics(clear_cache=True)\n",
    "\n",
    "    # Include the dataset name as a field in the metrics for visualization.\n",
    "    benign_metrics['roc'].update({'dataset': dataset_name})\n",
    "    benign_metrics['pr'].update({'dataset': dataset_name})\n",
    "    malign_metrics['roc'].update({'dataset': dataset_name})\n",
    "    malign_metrics['pr'].update({'dataset': dataset_name})\n",
    "\n",
    "    metrics = {'benign': benign_metrics, 'malign': malign_metrics}\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the datasets.\n",
    "dataset_metrics = []\n",
    "for dataset_name, dataloader in dataloaders:\n",
    "    metrics = get_predictions(dataset_name, dataloader, model)\n",
    "    dataset_metrics.append((dataset_name, metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC and PR Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot benign curves.\n",
    "benign_roc = [metrics['benign']['roc'] for dataset_name, metrics in dataset_metrics]\n",
    "benign_pr = [metrics['benign']['pr'] for dataset_name, metrics in dataset_metrics]\n",
    "\n",
    "plot_roc_pr(benign_roc, benign_pr, title='Benign', figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot malign curves.\n",
    "benign_roc = [metrics['malign']['roc'] for dataset_name, metrics in dataset_metrics]\n",
    "benign_pr = [metrics['malign']['pr'] for dataset_name, metrics in dataset_metrics]\n",
    "\n",
    "plot_roc_pr(benign_roc, benign_pr, title='Malign', figsize=(12, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midas_github",
   "language": "python",
   "name": "midas_github"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
